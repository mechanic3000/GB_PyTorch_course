{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFyFRoycApIqL9DQGnalOd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mechanic3000/GB_PyTorch_course/blob/Lesson_04/Lesson_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Урок 4. CNN Свертки\n",
        "  Обучите CNN (самописная) на CIFAR-100.\n",
        "\n",
        "  Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
        "\n",
        "  *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных.\n"
      ],
      "metadata": {
        "id": "fX8PRQzkejKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpsTbXhSeb0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
        "    return X_train, X_test\n",
        "\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]\n",
        "    \n",
        "trans_actions = transforms.Compose([transforms.Resize(44),\n",
        "                                    transforms.RandomCrop(32, padding=4), \n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7_IKN5Me4Nz",
        "outputId": "1d4b7960-0544-4459-db1e-b008eb6e653a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img, lbl in train_loader:\n",
        "  print(img.shape)\n",
        "  print(lbl[0])\n",
        "  plt.imshow(img[0].permute(1,2,0))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "yVjqc4gDgIJT",
        "outputId": "5734babe-1007-4024-e691-73129f49286a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "tensor(11)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3D7aWBQ1hs_f",
        "outputId": "784a2e54-8cb9-4b80-9777-bafb18d7759f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dp_three = nn.Dropout(0.2)\n",
        "        self.dp_four = nn.Dropout(0.2)\n",
        "        \n",
        "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
        "        self.conv_one = torch.nn.Conv2d(3, 30, 3)\n",
        "        self.bn_two = torch.nn.BatchNorm2d(30) \n",
        "        self.conv_two = torch.nn.Conv2d(30, 60, 3)\n",
        "        self.bn_three = torch.nn.BatchNorm2d(60)\n",
        "        self.conv_three = torch.nn.Conv2d(60, 120, 3)\n",
        "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
        "        self.fc1 = torch.nn.Linear(480, 200)\n",
        "        self.fc2 = torch.nn.Linear(200, 60)\n",
        "        self.out = torch.nn.Linear(60, 100)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn_one(x)\n",
        "        x = self.conv_one(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_two(x)\n",
        "        x = self.conv_two(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_three(x)\n",
        "        x = self.conv_three(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_four(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp_three(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dp_four(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.out(x)\n",
        "       \n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpLcCYNSh10U",
        "outputId": "7f65b508-2eae-417d-fed3-882196d90e34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp_three): Dropout(p=0.2, inplace=False)\n",
            "  (dp_four): Dropout(p=0.2, inplace=False)\n",
            "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_two): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_three): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=480, out_features=200, bias=True)\n",
            "  (fc2): Linear(in_features=200, out_features=60, bias=True)\n",
            "  (out): Linear(in_features=60, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "QluQA1lWiN5d"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybcMHrI0iQtU",
        "outputId": "4af7878f-95d8-41f0-a21d-9fbfefada12d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
            "            Conv2d-2           [-1, 30, 30, 30]             840\n",
            "       BatchNorm2d-3           [-1, 30, 15, 15]              60\n",
            "            Conv2d-4           [-1, 60, 13, 13]          16,260\n",
            "       BatchNorm2d-5             [-1, 60, 6, 6]             120\n",
            "            Conv2d-6            [-1, 120, 4, 4]          64,920\n",
            "       BatchNorm2d-7            [-1, 120, 2, 2]             240\n",
            "           Dropout-8                  [-1, 480]               0\n",
            "            Linear-9                  [-1, 200]          96,200\n",
            "          Dropout-10                  [-1, 200]               0\n",
            "           Linear-11                   [-1, 60]          12,060\n",
            "           Linear-12                  [-1, 100]           6,100\n",
            "================================================================\n",
            "Total params: 196,806\n",
            "Trainable params: 196,806\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.40\n",
            "Params size (MB): 0.75\n",
            "Estimated Total Size (MB): 1.16\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    net.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    net.eval()\n",
        "    loss_accumed = 0\n",
        "    for X, y in valid_loader:\n",
        "        output = net(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNs0j7Woi6G4",
        "outputId": "9d402f4c-7202-42fa-91d1-5d42d5f74543"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 79.23333740234375\n",
            "Epoch 1 valid_loss 78.04564666748047\n",
            "Epoch 2 valid_loss 81.78667449951172\n",
            "Epoch 3 valid_loss 74.61417388916016\n",
            "Epoch 4 valid_loss 74.60105895996094\n",
            "Epoch 5 valid_loss 72.28382110595703\n",
            "Epoch 6 valid_loss 68.74481964111328\n",
            "Epoch 7 valid_loss 69.60255432128906\n",
            "Epoch 8 valid_loss 77.77237701416016\n",
            "Epoch 9 valid_loss 70.19519805908203\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageNet Resnet-50"
      ],
      "metadata": {
        "id": "-JGG9PjDmlsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiEP-ampmoAX",
        "outputId": "f713e0e1-2372-4beb-c2eb-d17b81b987ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in list(resnet50.parameters())[:]:\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "CkUBHi7moO9J"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.fc = nn.Linear(2048, 100)"
      ],
      "metadata": {
        "id": "tI6BPLggm_aD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet50.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHHiDsGNrJKw",
        "outputId": "9469c800-9754-43a8-b787-c860c4891ae0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 204,900\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.86\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 96.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "IAuSr1XVs5hp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name,param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "qrxSC7Kzow3-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01J4tvI6om-m",
        "outputId": "a8df3ff2-f76c-41dc-f1bc-0b7dfd042e4c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 1.0272e-02,  5.6018e-05,  6.2499e-03,  ..., -1.3558e-02,\n",
              "          -1.3317e-02,  7.9372e-03],\n",
              "         [-8.8711e-04,  1.3159e-03, -1.2087e-02,  ..., -1.3500e-03,\n",
              "           3.4744e-03,  2.3402e-03],\n",
              "         [ 9.3268e-03,  1.5787e-02, -1.1798e-02,  ...,  9.5738e-03,\n",
              "           1.3147e-02, -1.6269e-03],\n",
              "         ...,\n",
              "         [ 9.7009e-04, -1.5805e-02,  7.3765e-03,  ..., -1.6814e-02,\n",
              "          -8.1301e-03, -9.4185e-04],\n",
              "         [-1.0362e-02,  1.5177e-02, -1.7904e-02,  ...,  8.0575e-03,\n",
              "          -1.1224e-02,  1.4106e-02],\n",
              "         [ 8.9248e-03,  1.5482e-02, -1.8212e-02,  ...,  1.7819e-02,\n",
              "           1.7437e-02,  2.1167e-02]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-9.2554e-03,  1.7022e-02,  8.4291e-03, -1.4575e-02, -1.9235e-02,\n",
              "          1.7148e-02,  1.6710e-02,  1.1158e-02, -2.2039e-02,  1.5829e-02,\n",
              "         -1.6304e-02,  1.4651e-02, -5.2885e-03, -1.1013e-02,  2.6113e-04,\n",
              "         -1.7770e-02, -1.5087e-02,  1.3776e-02,  1.7795e-02,  9.7486e-03,\n",
              "          1.4801e-02, -4.1367e-03,  7.2588e-03, -1.6871e-02,  1.4194e-02,\n",
              "          1.4137e-02, -6.8615e-03,  2.0762e-02,  2.1166e-04,  3.8888e-03,\n",
              "          1.7592e-02,  1.4402e-02, -2.7057e-03, -3.1343e-04, -1.9929e-02,\n",
              "         -9.1182e-05,  1.4072e-02, -1.8716e-02, -2.1996e-02,  1.9224e-02,\n",
              "         -5.3333e-03, -2.0087e-02,  1.1664e-02,  1.9713e-02, -3.4320e-03,\n",
              "         -1.0365e-02, -2.0049e-02, -7.6516e-03,  1.4360e-03,  1.2929e-02,\n",
              "          8.7491e-03,  2.0980e-02, -1.2163e-02,  5.5750e-03, -3.9731e-03,\n",
              "          5.2131e-03, -1.6630e-02,  1.9272e-02,  1.1802e-02,  4.8617e-03,\n",
              "          1.3915e-02,  1.1910e-02,  1.3328e-02,  1.7509e-02,  2.0036e-03,\n",
              "          6.1669e-03, -1.9362e-02,  1.6107e-02,  1.1425e-02,  7.2582e-03,\n",
              "          3.2230e-03,  1.6126e-02,  4.2972e-03, -7.0590e-03, -9.2188e-03,\n",
              "         -2.1295e-02, -4.8993e-03, -7.9862e-03, -1.9779e-02, -2.1446e-02,\n",
              "          1.8337e-02, -1.8427e-02, -1.1796e-02, -8.9570e-03,  1.0578e-03,\n",
              "          1.5619e-02,  2.5608e-03,  6.3845e-03,  1.6756e-02, -1.6277e-02,\n",
              "          9.0800e-03, -1.8616e-02, -9.5824e-03, -1.0228e-02, -1.1692e-02,\n",
              "          1.2272e-02, -2.2079e-03, -7.9371e-03, -3.1016e-03,  5.4519e-03],\n",
              "        device='cuda:0', requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    resnet50.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    resnet50.eval()\n",
        "    loss_accumed = 0\n",
        "    for X, y in valid_loader:\n",
        "        output = resnet50(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g43oJvBo5Hg",
        "outputId": "726c7550-29a5-452a-88a7-3c01bf4190e1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 74.32579040527344\n",
            "Epoch 1 valid_loss 73.46196746826172\n",
            "Epoch 2 valid_loss 72.03599548339844\n",
            "Epoch 3 valid_loss 72.33522033691406\n",
            "Epoch 4 valid_loss 71.48048400878906\n",
            "Epoch 5 valid_loss 72.27799224853516\n",
            "Epoch 6 valid_loss 71.0646743774414\n",
            "Epoch 7 valid_loss 70.5198745727539\n",
            "Epoch 8 valid_loss 70.52606964111328\n",
            "Epoch 9 valid_loss 71.2808609008789\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageNet Resnet-50 с аугментацией данных."
      ],
      "metadata": {
        "id": "s_yX-nWot1AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans_actions = transforms.Compose([transforms.Resize(256),\n",
        "                                    transforms.RandomCrop(224, padding=4),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225])])\n",
        "valid_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "JXHiq_xXtvD2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in list(resnet50.parameters())[:]:\n",
        "  param.requires_grad = False\n",
        "\n",
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "params_to_update = []\n",
        "for name,param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Om3etvlW1mYT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    resnet50.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    resnet50.eval()\n",
        "    loss_accumed = 0\n",
        "    for X, y in valid_loader:\n",
        "        output = resnet50(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naUpCODuuKaE",
        "outputId": "2199a9f0-700a-4e83-bbf7-a3638d437447"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 73.86024475097656\n",
            "Epoch 1 valid_loss 72.60516357421875\n",
            "Epoch 2 valid_loss 71.51356506347656\n",
            "Epoch 3 valid_loss 72.29499053955078\n",
            "Epoch 4 valid_loss 72.88732147216797\n",
            "Epoch 5 valid_loss 70.7462387084961\n",
            "Epoch 6 valid_loss 69.50745391845703\n",
            "Epoch 7 valid_loss 70.12284088134766\n",
            "Epoch 8 valid_loss 71.24120330810547\n",
            "Epoch 9 valid_loss 69.21424102783203\n",
            "Training is finished!\n"
          ]
        }
      ]
    }
  ]
}